{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Lab6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vnsa8VMYP-v"
      },
      "source": [
        "<a \n",
        "href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab6.ipynb\"\n",
        "  target=\"_parent\">\n",
        "  <img\n",
        "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
        "    alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Lab 6: Sequence-to-sequence models\n",
        "\n",
        "### Description:\n",
        "For this lab, you will code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
        "\n",
        "This lab will help you develop several new skills, as well as understand some best practices needed for building large models. In addition, we'll be able to create networks that generate neat text!\n",
        "\n",
        "### Deliverable:\n",
        "- Fill in the code for the RNN (using PyTorch's built-in GRU).\n",
        "- Fill in the training loop\n",
        "- Fill in the evaluation loop. In this loop, rather than using a validation set, you will sample text from the RNN.\n",
        "- Implement your own GRU cell.\n",
        "- Train your RNN on a new domain of text (Star Wars, political speeches, etc. - have fun!)\n",
        "\n",
        "### Grading Standards:\n",
        "- 20% Implementation the RNN\n",
        "- 20% Implementation training loop\n",
        "- 20% Implementation of evaluation loop\n",
        "- 20% Implementation of your own GRU cell\n",
        "- 20% Training of your RNN on a domain of your choice\n",
        "\n",
        "### Tips:\n",
        "- Read through all the helper functions, run them, and make sure you understand what they are doing\n",
        "- At each stage, ask yourself: What should the dimensions of this tensor be? Should its data type be float or int? (int is called `long` in PyTorch)\n",
        "- Don't apply a softmax inside the RNN if you are using an nn.CrossEntropyLoss (this module already applies a softmax to its input).\n",
        "\n",
        "### Example Output:\n",
        "An example of my final samples are shown below (more detail in the\n",
        "final section of this writeup), after 150 passes through the data.\n",
        "Please generate about 15 samples for each dataset.\n",
        "\n",
        "<code>\n",
        "And ifte thin forgision forward thene over up to a fear not your\n",
        "And freitions, which is great God. Behold these are the loss sub\n",
        "And ache with the Lord hath bloes, which was done to the holy Gr\n",
        "And appeicis arm vinimonahites strong in name, to doth piseling \n",
        "And miniquithers these words, he commanded order not; neither sa\n",
        "And min for many would happine even to the earth, to said unto m\n",
        "And mie first be traditions? Behold, you, because it was a sound\n",
        "And from tike ended the Lamanites had administered, and I say bi\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2i_QpSsWG4c"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 0: Readings, data loading, and high level training\n",
        "\n",
        "---\n",
        "\n",
        "There is a tutorial here that will help build out scaffolding code, and get an understanding of using sequences in pytorch.\n",
        "\n",
        "* Read the following\n",
        "\n",
        "> * [Pytorch sequence-to-sequence tutorial](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) (You will be implementing the decoder, not the encoder, as we are not doing sequence-to-sequence translation.)\n",
        "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7bdZWxvJrsx",
        "outputId": "c3e89c7d-94a4-43d3-e5ab-dbdadd6a4d52"
      },
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        " \n",
        "import pdb\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-15 23:23:04--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 3.221.194.245, 52.44.149.188, 54.86.243.162, ...\n",
            "Connecting to piazza.com (piazza.com)|3.221.194.245|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2021-10-15 23:23:04--  https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving cdn-uploads.piazza.com (cdn-uploads.piazza.com)... 13.225.229.42, 13.225.229.107, 13.225.229.31, ...\n",
            "Connecting to cdn-uploads.piazza.com (cdn-uploads.piazza.com)|13.225.229.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "./text_files.tar.gz 100%[===================>]   1.46M  9.43MB/s    in 0.2s    \n",
            "\n",
            "2021-10-15 23:23:05 (9.43 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.3.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "file_len = 2579888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxBeKeNjJ0NQ",
        "outputId": "c5958c0c-5763-46b4-ccbf-fd4425135928"
      },
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]\n",
        "  \n",
        "print(random_chunk())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In my just censure, in my true opinion!\n",
            "Alack, for lesser knowledge! how accursed\n",
            "In being so blest! There may be in the cup\n",
            "A spider steep'd, and one may drink, depart,\n",
            "And yet partake no venom, for h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On0_WitWJ99e",
        "outputId": "43a35de3-6822-49f8-e272-84e45cb0abf0"
      },
      "source": [
        "import torch\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long()\n",
        "  for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "  return tensor\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: Creating your own GRU cell \n",
        "\n",
        "**(Come back to this later - its defined here so that the GRU will be defined before it is used)**\n",
        "\n",
        "---\n",
        "\n",
        "The cell that you used in Part 1 was a pre-defined Pytorch layer. Now, write your own GRU class using the same parameters as the built-in Pytorch class does.\n",
        "\n",
        "Please do not look at the documentation's code for the GRU cell definition. The answer is right there in the code, and in theory, you could just cut-and-paste it. This bit is on your honor!\n",
        "\n",
        "**TODO:**\n",
        "* Create a custom GRU cell\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavAv50ZKQ-F"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(GRU, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        \"\"\"self.W_iz = nn.Linear(input_size, hidden_size)\n",
        "        self.W_ir = nn.Linear(input_size, hidden_size)\n",
        "        self.W_in = nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        self.W_hz = nn.Linear(hidden_size, hidden_size)\n",
        "        self.W_hr = nn.Linear(hidden_size, hidden_size)\n",
        "        self.W_hn = nn.Linear(hidden_size, hidden_size)\"\"\"\n",
        "\n",
        "        self.W_ir_list = nn.ModuleList([nn.Linear(input_size, hidden_size) for i in range(num_layers)])\n",
        "        self.W_iz_list = nn.ModuleList([nn.Linear(input_size, hidden_size) for i in range(num_layers)])\n",
        "        self.W_in_list = nn.ModuleList([nn.Linear(input_size, hidden_size) for i in range(num_layers)])\n",
        "\n",
        "        self.W_hr_list = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for i in range(num_layers)])\n",
        "        self.W_hz_list = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for i in range(num_layers)])\n",
        "        self.W_hn_list = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for i in range(num_layers)])\n",
        "\n",
        "    def forward(self, inputs, hidden):\n",
        "        # Each layer does the following:\n",
        "        # r_t = sigmoid(W_ir*x_t + b_ir + W_hr*h_(t-1) + b_hr)\n",
        "        # z_t = sigmoid(W_iz*x_t + b_iz + W_hz*h_(t-1) + b_hz)\n",
        "        # n_t = tanh(W_in*x_t + b_in + r_t**(W_hn*h_(t-1) + b_hn))\n",
        "        # h_(t) = (1 - z_t)**n_t + z_t**h_(t-1)\n",
        "        # Where ** is hadamard product (not matrix multiplication, but elementwise multiplication)\n",
        "        \n",
        "        \"\"\"# Single Layer\n",
        "        z_t = torch.sigmoid(self.W_iz(inputs) + self.W_hz(hidden))\n",
        "        r_t = torch.sigmoid(self.W_ir(inputs) + self.W_hr(hidden))\n",
        "        n_t = torch.tanh(self.W_in(inputs) + r_t * self.W_hn(hidden))\n",
        "        h_t = (1 - z_t) * n_t + z_t * hidden\n",
        "        \n",
        "        outputs = h_t[-1]\n",
        "        hiddens = torch.cat(h_t, 0)\"\"\"\n",
        "\n",
        "        \"\"\"# Multi layer\n",
        "        z_t_list = [torch.sigmoid(self.W_iz_list[i](inputs) + self.W_hz_list[i](hidden[i])) for i in range(self.num_layers)]\n",
        "        r_t_list = [torch.sigmoid(self.W_ir_list[i](inputs) + self.W_hr_list[i](hidden[i])) for i in range(self.num_layers)]\n",
        "        n_t_list = [torch.tanh(self.W_in_list[i](inputs) + r_t * self.W_hn_list[i](hidden[i])) for i in range(self.num_layers)]\n",
        "        h_t_list = [(1 - z_t[i]) * n_t[i] + z_t[i] * hidden[i] for i in range(self.num_layers)]\n",
        "\n",
        "        outputs_list = h_t_list[-1]\n",
        "        hiddens_list = torch.cat(tuple(h_t_list), 0)\"\"\"\n",
        "        h_t = hidden\n",
        "        for i in range(self.num_layers):\n",
        "            z_t = torch.sigmoid(self.W_iz_list[i](inputs) + self.W_hz_list[i](hidden)) \n",
        "            r_t = torch.sigmoid(self.W_ir_list[i](inputs) + self.W_hr_list[i](hidden))\n",
        "            n_t = torch.tanh(self.W_in_list[i](inputs) + r_t * self.W_hn_list[i](hidden))\n",
        "            h_t = (1 - z_t) * n_t + z_t * h_t\n",
        "\n",
        "        return h_t, h_t\n",
        "  \n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Part 1: Building a sequence to sequence model\n",
        "\n",
        "---\n",
        "\n",
        "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
        "\n",
        "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n",
        "\n",
        "\n",
        "**TODO:**\n",
        "* Create an RNN class that extends from nn.Module.\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6tNdEnzWj5F"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        # My stuff\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = GRU(hidden_size, hidden_size, n_layers)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_char, hidden):\n",
        "        # by reviewing the documentation, construct a forward function that properly uses the output of the GRU\n",
        "        output = self.embedding(input_char).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output[0])\n",
        "\n",
        "        return output, hidden\n",
        "        \n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.n_layers, 1, self.hidden_size)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrhXghEPKD-5"
      },
      "source": [
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpiGObbBX0Mr"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "We now want to be able to train our network, and sample text after training.\n",
        "\n",
        "This function outlines how training a sequence style network goes. \n",
        "\n",
        "**TODO:**\n",
        "* Fill in the pieces.\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIsD9aH3iF10"
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ALC3Pf8Kbsi"
      },
      "source": [
        "# NOTE: decoder_optimizer, decoder, and criterion will be defined below as global variables in Part 5\n",
        "\n",
        "def train(inp, target):\n",
        "    ## initialize hidden layers, set up gradient and loss \n",
        "        # your code here\n",
        "    ## /\n",
        "    input_length = inp.size(0)\n",
        "    target_length = target.size(0)\n",
        "\n",
        "    decoder_optimizer.zero_grad()\n",
        "    hidden = decoder.init_hidden()\n",
        "    loss = 0\n",
        "    # My Stuff\n",
        "    for i, char in enumerate(inp):\n",
        "        output, hidden = decoder(char, hidden)\n",
        "        curr_loss = criterion(output, target[i].unsqueeze(0))\n",
        "        loss += curr_loss\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "You can at this time, if you choose, also write out your train loop boilerplate that samples random sequences and trains your RNN. This will be helpful to have working before writing your own GRU class.\n",
        "\n",
        "If you are finished training, or during training, and you want to sample from the network you may consider using the following function. If your RNN model is instantiated as `decoder`then this will probabilistically sample a sequence of length `predict_len`\n",
        "\n",
        "**TODO:**\n",
        "* Fill out the evaluate function to generate text frome a primed string\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-bp-OZ1KjNh"
      },
      "source": [
        "def sample_outputs(output, temperature):\n",
        "    \"\"\"Takes in a vector of unnormalized probability weights and samples a character from the distribution\"\"\"\n",
        "    # As temperature approaches 0, this sampling function becomes argmax (no randomness)\n",
        "    # As temperature approaches infinity, this sampling function becomes a purely random choice\n",
        "    return torch.multinomial(torch.exp(output / temperature), 1)\n",
        "\n",
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    ## initialize hidden state, initialize other useful variables\n",
        "        # your code here\n",
        "    ## /\n",
        "\n",
        "    prediction = list(prime_str)\n",
        "    hidden = decoder.init_hidden()\n",
        "    \n",
        "    for char in prime_str:\n",
        "        output, hidden = decoder(char_tensor(char), hidden)\n",
        "\n",
        "    next_char_pred = prime_str[-1]\n",
        "    \n",
        "    for _ in range(predict_len):\n",
        "        output, hidden = decoder(char_tensor(next_char_pred), hidden)\n",
        "        last_char_index = sample_outputs(output, temperature)\n",
        "        next_char_pred = all_characters[last_char_index]\n",
        "        prediction.append(next_char_pred)\n",
        "\n",
        "    final_prediction = \"\".join(prediction)\n",
        "    return final_prediction"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du4AGA8PcFEW"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 4: (Create a GRU cell, requirements above)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Part 5: Run it and generate some text!\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**TODO:** \n",
        "* Create some cool output\n",
        "\n",
        "**DONE:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Assuming everything has gone well, you should be able to run the main function in the scaffold code, using either your custom GRU cell or the built in layer, and see output something like this. I trained on the “lotr.txt” dataset, using chunk_length=200, hidden_size=100 for 2000 epochs. These are the results, along with the prime string:\n",
        "\n",
        "---\n",
        "\n",
        " G:\n",
        " \n",
        " Gandalf was decrond. \n",
        "'All have lord you. Forward the road at least walk this is stuff, and \n",
        "went to the long grey housel-winding and kindled side was a sleep pleasuring, I do long \n",
        "row hrough. In  \n",
        "\n",
        " lo:\n",
        " \n",
        " lost death it. \n",
        "'The last of the gatherings and take you,' said Aragorn, shining out of the Gate. \n",
        "'Yes, as you there were remembaused to seen their pass, when? What \n",
        "said here, such seven an the sear \n",
        "\n",
        " lo:\n",
        " \n",
        " low, and frod to keepn \n",
        "Came of their most. But here priced doubtless to an Sam up is \n",
        "masters; he left hor as they are looked. And he could now the long to stout in the right fro horseless of \n",
        "the like \n",
        "\n",
        " I:\n",
        " \n",
        " I had been the \n",
        "in his eyes with the perushed to lest, if then only the ring and the legended \n",
        "of the less of the long they which as the \n",
        "enders of Orcovered and smood, and the p \n",
        "\n",
        " I:\n",
        " \n",
        " I they were not the lord of the hoomes. \n",
        "Home already well from the Elves. And he sat strength, and we \n",
        "housed out of the good of the days to the mountains from his perith. \n",
        "\n",
        "'Yess! Where though as if  \n",
        "\n",
        " Th:\n",
        " \n",
        " There yarden \n",
        "you would guard the hoor might. Far and then may was \n",
        "croties, too began to see the drumbred many line \n",
        "and was then hoard walk and they heart, and the chair of the \n",
        "Ents of way, might was \n",
        "\n",
        " G:\n",
        " \n",
        " Gandalf \n",
        "been lat of less the round of the stump; both and seemed to the trees and perished they \n",
        "lay are speered the less; and the wind the steep and have to she \n",
        "precious. There was in the oonly went \n",
        "\n",
        " wh:\n",
        " \n",
        " which went out of the door. \n",
        "Hull the King and of the The days of his brodo \n",
        "stumbler of the windard was a thing there, then it been shining langing \n",
        "to him poor land. They hands; though they seemed ou \n",
        "\n",
        " ra:\n",
        " \n",
        " rather,' have all the least deather \n",
        "down of the truven beginning to the house of sunk. \n",
        "'Nark shorts of the Eyes of the Gate your great nothing as Eret. \n",
        "'I wander trust horn, and there were not, it  \n",
        "\n",
        " I:\n",
        " \n",
        " I can have no mind \n",
        "together! Where don't may had one may little blung \n",
        "terrible to tales. And turn and Gandalf shall be not to as only the Cattring \n",
        "not stopped great the out them forms. On they she lo \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nXFeCmdKodw"
      },
      "source": [
        "import time\n",
        "n_epochs = 5000\n",
        "print_every = 200\n",
        "plot_every = 10\n",
        "hidden_size = 200\n",
        "n_layers = 3\n",
        "lr = 0.001\n",
        " \n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKfozqw-6eqb",
        "outputId": "20f9b952-d380-4393-92ce-1b38ddef2ea6"
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set())       \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "      print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[160.42864513397217 (200 4%) 2.1695]\n",
            "Wh banl ind be her me bared of \n",
            "of wand. The same her nough to in the sore saod \n",
            "\n",
            "\n",
            "\n",
            "vhawe ste lloing f \n",
            "\n",
            "[319.6418743133545 (400 8%) 1.8735]\n",
            "Whind not sull and rode said sester gonterr. \n",
            "But said But have waly not had watf lustorn. 'Houred was \n",
            "\n",
            "[478.13315892219543 (600 12%) 1.7835]\n",
            "Whern: courseb't it, but there whrlave \n",
            "\n",
            "lirster of thoughty on that the, \n",
            "and down the grood \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "M \n",
            "\n",
            "[636.7872338294983 (800 16%) 1.7616]\n",
            "Whapen away alrong' he Grecoor a down, of (are Sang the pape and \n",
            "lizt that it then mirel can this tow \n",
            "\n",
            "[795.7131023406982 (1000 20%) 1.5979]\n",
            "Wher and some spoken hornes a \n",
            "\n",
            "day lought and he pace mask. \n",
            "\n",
            "Alto supping of the quesening that they \n",
            "\n",
            "[953.9603943824768 (1200 24%) 1.7666]\n",
            "Whind now. It insen me fough him. \n",
            "\n",
            "1now \n",
            "he mank the Belpane a laster gazed wall they bate of the dar \n",
            "\n",
            "[1111.605400800705 (1400 28%) 1.7430]\n",
            "Whing iite op the green with the sside the time this too his \n",
            "spoke their with the blindle to the hear \n",
            "\n",
            "[1268.8375420570374 (1600 32%) 1.6269]\n",
            "Whalf. Tom the trits me' \n",
            "nor morning of the Mines of hies figed. They nathel must wish a forner to es \n",
            "\n",
            "[1426.5366184711456 (1800 36%) 1.9097]\n",
            "Whear door. V it you thing the passed a broy \n",
            "the words they leave we not the words to well him be the \n",
            "\n",
            "[1583.7206773757935 (2000 40%) 1.6344]\n",
            "Whor of the day the orecion will been \n",
            "a ganew now when the put more of there say. We must so ever wil \n",
            "\n",
            "[1740.9330956935883 (2200 44%) 1.6071]\n",
            "Whicher, \n",
            "of the dare, darking swift of the Gimlains and them about the window with by the River of yo \n",
            "\n",
            "[1898.1168148517609 (2400 48%) 1.7604]\n",
            "Wher felling about the kingly hung my vale and the more mecious or in sing to the wind in trust anyfor \n",
            "\n",
            "[2055.3723573684692 (2600 52%) 1.5485]\n",
            "Whap at left their eyes at lifter all the went. But my time more why it is not and the stear with a mo \n",
            "\n",
            "[2211.535734653473 (2800 56%) 1.6619]\n",
            "Whmate and the direst of gried in the rong and left. \n",
            "\n",
            "'Not house-traded the streak of cords for eneas \n",
            "\n",
            "[2368.2496931552887 (3000 60%) 1.5295]\n",
            "Whalmed to the stone old his bat me that be then he said, the larres of \n",
            "then should be feel were that \n",
            "\n",
            "[2523.9975035190582 (3200 64%) 1.8595]\n",
            "Whered the \n",
            "great \n",
            "were come of the way, and he was the caved be the hobbit, and in a must face in the \n",
            "\n",
            "[2680.964131832123 (3400 68%) 1.5253]\n",
            "Whind them and closs to recigull of More down now. \n",
            "All than \n",
            "come of the \n",
            "twithing he \n",
            "amounder it ag \n",
            "\n",
            "[2835.904294729233 (3600 72%) 1.4962]\n",
            "Whind the word beasy make journed \n",
            "out, and his discape; but his command more the \n",
            "Ray of \n",
            "the Sabow,  \n",
            "\n",
            "[2990.5850234031677 (3800 76%) 1.6439]\n",
            "Wh and every have brountly heard \n",
            "and the gateing of a riders \n",
            "the met voice to Orts \n",
            "visis of the wea \n",
            "\n",
            "[3144.322421312332 (4000 80%) 1.4838]\n",
            "Whines of water most that rust to a long \n",
            "and \n",
            "not feet to onet them that to kings within stristed. He \n",
            "\n",
            "[3298.3112552165985 (4200 84%) 1.4108]\n",
            "Whing it atry and became the Eneyn against the gate the some to Sam. \n",
            "\n",
            "'Let the follow thander my cour \n",
            "\n",
            "[3452.357053041458 (4400 88%) 1.4626]\n",
            "Which \n",
            "suddennels of the rivers of the daining and lorts of the \n",
            "isnot stone sid path since a great ch \n",
            "\n",
            "[3604.779992580414 (4600 92%) 1.4685]\n",
            "Whind I fancy, and if he was him upon the blassed his like it will heard, some sound upon the trees an \n",
            "\n",
            "[3758.762780189514 (4800 96%) 1.5700]\n",
            "Whant their light who eye-lands had leance \n",
            "with his been his a which not they caused to the Tower mas \n",
            "\n",
            "[3913.2664234638214 (5000 100%) 1.3240]\n",
            "Whout it. My now now a ancie gatched. 'Or said his time now morning man. Forwards began to Edright was \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee0so6aKJ5L8",
        "outputId": "4f151a1a-6a9d-4a43-e613-4078261baa68"
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(start_strings[start], 200), '\\n')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Th\n",
            " The water flose with a night aprost the southem between that is squest \n",
            "the yigh only rest to the Ease in they leadin as not \n",
            "to upsent and a land to some was one \n",
            "and \n",
            "gather bone: see you should, and  \n",
            "\n",
            " he\n",
            " heds and bowing \n",
            "brought the call had sleeping. Thenwayed and foots and \n",
            "the light of the flashed and they came a burred to \n",
            "the light. \n",
            "\n",
            "'It you was side at did. But with a dark a wilenday and lender a \n",
            "\n",
            " wh\n",
            " whictaning about the Dwarf. I will well behind when from the wight may forest dragolt. \n",
            "\n",
            "Then I would now did the Ring which to \n",
            "eyes hard and climbh. There have not men and I wood. To fall all trying o \n",
            "\n",
            " ca\n",
            " carch for for my clo! Frodo. ' Frodo was much from him of the call \n",
            "as ' he said?' \n",
            "\n",
            "'I do you are years for shame and \n",
            "\n",
            "door. He live else from your will be we muside time and clast would samber in the \n",
            "\n",
            " wh\n",
            " whouth. He light with here in the narrow here and had \n",
            "rust, and the stond a wind. Muider and Merry \n",
            "before the chair. I foot. They cool still the same there felt from you arms more was must came a far  \n",
            "\n",
            " Th\n",
            " Thirhed little of the Suntle of \n",
            "return to remust binds of the remottle to still me to the withore all to \n",
            "chain in the are; from his beet come now dead. \n",
            "\n",
            "'Suddenly that was are is, and what \n",
            "River che \n",
            "\n",
            " ca\n",
            " cased his mournet that to him; and that: \n",
            "least in the horrits on the North and under the Ring clouds where when a wrields know to his lies ham \n",
            "clearned to be remoursed when and like them; in someI sto \n",
            "\n",
            " Th\n",
            " Though his faces that you could \n",
            "they can now a darkly for here what when Frodo's leaning.' \n",
            "\n",
            "There's dreadwards in the white to see the might seems in the which a pain of the \n",
            "shadow of the paused from \n",
            "\n",
            " G\n",
            " Godol and unexe and company and drinking out in the put of xoin and drack of the sound nothing was hummering and much fell and clouds many returned. 'Wusine. I don't you are to pressed and all not will \n",
            "\n",
            " ra\n",
            " ramon of the Shirrow in \n",
            "mind that you have a south and some sore. He wandeling and fain what is some flat cried were great only the's \n",
            "wheep at learn clear, near away and now of his eying black it are  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJhgDc2IauPE"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 6: Generate output on a different dataset\n",
        "\n",
        "---\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "* Choose a textual dataset. Here are some [text datasets](https://www.kaggle.com/datasets?tags=14104-text+data%2C13205-text+mining) from Kaggle \n",
        "\n",
        "* Generate some decent looking results and evaluate your model's performance (say what it did well / not so well)\n",
        "\n",
        "**DONE:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BilOyMX3inUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bfbedfe-4ad7-49f3-8a6b-5be1b105baa4"
      },
      "source": [
        "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "! tar -xzf text_files.tar.gz\n",
        "! pip install unidecode\n",
        "! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        " \n",
        "import pdb\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "file = unidecode.unidecode(open('./text_files/tiny_shakespeare.txt').read())\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-16 20:19:24--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
            "Resolving piazza.com (piazza.com)... 52.54.75.23, 52.44.149.188, 3.221.194.245, ...\n",
            "Connecting to piazza.com (piazza.com)|52.54.75.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
            "--2021-10-16 20:19:25--  https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
            "Resolving cdn-uploads.piazza.com (cdn-uploads.piazza.com)... 13.249.137.97, 13.249.137.102, 13.249.137.78, ...\n",
            "Connecting to cdn-uploads.piazza.com (cdn-uploads.piazza.com)|13.249.137.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1533290 (1.5M) [application/x-gzip]\n",
            "Saving to: ‘./text_files.tar.gz’\n",
            "\n",
            "./text_files.tar.gz 100%[===================>]   1.46M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-10-16 20:19:25 (25.6 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
            "\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "file_len = 1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePFwl71WwlsJ"
      },
      "source": [
        "import time\n",
        "n_epochs = 5000\n",
        "print_every = 200\n",
        "plot_every = 10\n",
        "hidden_size = 200\n",
        "n_layers = 5\n",
        "lr = 0.0005\n",
        " \n",
        "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfYk0Uf5wzFX",
        "outputId": "7939808d-4ede-4dcf-c0b7-9a6b42e389b5"
      },
      "source": [
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set())       \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
        "      print(evaluate('Wh', 100), '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[266.93727374076843 (200 4%) 2.5962]\n",
            "Whe coe,\n",
            "\n",
            "GyRYRRENRCO:\n",
            "Fat dusing thas. I bhamI brengr:\n",
            "Ney on tho fown yor, brealintindi\n",
            "Ancs foreetO \n",
            "\n",
            "[528.9766573905945 (400 8%) 2.1066]\n",
            "Wh the crunce weends, my wem, west of have thou sild cront thy sit roud mod heach frumed wour bener th \n",
            "\n",
            "[791.072660446167 (600 12%) 2.0109]\n",
            "Wh?\n",
            "Whee 'toryer is puin, and I cundall then feppom contien beere, wilintss my preally coth your to th \n",
            "\n",
            "[1050.7609705924988 (800 16%) 2.0047]\n",
            "Wher'd whold the mome, of as a? in thee dome hear goar traie\n",
            "What thou dy hiuld hick for jome his cith \n",
            "\n",
            "[1311.8214690685272 (1000 20%) 2.0299]\n",
            "Whary the the canour so co veagn-to word to sold\n",
            "And love a inten us the rome the speathy denouly.\n",
            "\n",
            "LU \n",
            "\n",
            "[1571.7708387374878 (1200 24%) 1.8768]\n",
            "Whall no mice amp on the senst I was mided upolled in the good bacher to can pit refere\n",
            "The pursel.\n",
            "\n",
            "P \n",
            "\n",
            "[1830.417935848236 (1400 28%) 1.8942]\n",
            "Whillea of with will to have lord, den\n",
            "And Countly this eyech grofe;\n",
            "He wangings---\n",
            "\n",
            "LAMIOLA:\n",
            "Reave a  \n",
            "\n",
            "[2089.6983675956726 (1600 32%) 1.7992]\n",
            "Whand sudury.\n",
            "\n",
            "ORTIO:\n",
            "The breass.\n",
            "\n",
            "Crowf Vess your scorp'd her shall and gother,\n",
            "Frimst there thee, an \n",
            "\n",
            "[2346.585030078888 (1800 36%) 1.9050]\n",
            "Whilace that that this worsh all her lott.\n",
            "\n",
            "BOLIO:\n",
            "And for the holder,\n",
            "Have at his fair\n",
            "As the simbard \n",
            "\n",
            "[2603.0220165252686 (2000 40%) 1.7942]\n",
            "Wha\n",
            "brother:\n",
            "And nackily no?\n",
            "\n",
            "HORTENRY:\n",
            "Thou not that varder it inat with me, deeire monies in fors! T \n",
            "\n",
            "[2857.085995912552 (2200 44%) 1.7100]\n",
            "Whate of not man, the to the hather say on long.\n",
            "From rament her both comnot, him sould then with of f \n",
            "\n",
            "[3111.037036180496 (2400 48%) 1.7832]\n",
            "Where to what, for a surget and the meniting.\n",
            "\n",
            "VARULET:\n",
            "Sonour,\n",
            "And reseet:\n",
            "Inders to preturio, and pr \n",
            "\n",
            "[3365.9710125923157 (2600 52%) 1.8495]\n",
            "Whatthan good not of it as me one his proyous sointly begue and the have he priest a gook, the well\n",
            "Is \n",
            "\n",
            "[3623.3769183158875 (2800 56%) 1.8163]\n",
            "Whather Bight,\n",
            "But is this mind thee her, think thee, and stand thy lord? hear,\n",
            "And wirth a ghare;\n",
            "His \n",
            "\n",
            "[3881.8420889377594 (3000 60%) 1.4672]\n",
            "Whalt he\n",
            "percausbands, he rame to this love me take:\n",
            "Were not, anstrandest well's becomptard, him,\n",
            "The \n",
            "\n",
            "[4140.546961307526 (3200 64%) 1.6601]\n",
            "Wherger;\n",
            "And this morria.\n",
            "\n",
            "DUKE VINCENSIO:\n",
            "Petch to the subself\n",
            "And have shistak's form'd, tell shall  \n",
            "\n",
            "[4398.540860652924 (3400 68%) 1.5412]\n",
            "What and you shoices housele muted a matterful ston the eam,\n",
            "We like a mine the dead the lest.\n",
            "\n",
            "Nurse: \n",
            "\n",
            "[4657.994270086288 (3600 72%) 1.9244]\n",
            "Whak is the lord, she let ever Longarid,\n",
            "I will was a good contage in must neven ere wones to let Yerv \n",
            "\n",
            "[4915.7839250564575 (3800 76%) 1.5658]\n",
            "When poor so for us and lost see I both in no can\n",
            "With my lands, my house on you lide and love all the \n",
            "\n",
            "[5172.99165558815 (4000 80%) 1.6073]\n",
            "Whild, by the puce our same forture the vost? pardured or remend and that like in the gone you show th \n",
            "\n",
            "[5427.568496704102 (4200 84%) 1.6244]\n",
            "Whard's doply father my partion.\n",
            "\n",
            "BRUTUS:\n",
            "The king!\n",
            "\n",
            "MONTIO:\n",
            "We have not---one free stray not that you \n",
            "\n",
            "[5682.323410511017 (4400 88%) 1.4929]\n",
            "Whall me for the cousin well of the city again.\n",
            "\n",
            "BIANCE:\n",
            "Methink to my fawn stand, and be all this dau \n",
            "\n",
            "[5939.0928728580475 (4600 92%) 1.5095]\n",
            "Whilds I am say the crace:\n",
            "Tay, we king.\n",
            "\n",
            "POMPEY:\n",
            "As one as in he hand must no, I come thee:\n",
            "Renother  \n",
            "\n",
            "[6197.706566095352 (4800 96%) 1.7090]\n",
            "Whow not for land.\n",
            "\n",
            "PETRUCHILA:\n",
            "Let clother speak to did master of though a king mother, and hear your \n",
            "\n",
            "[6455.995445251465 (5000 100%) 1.6194]\n",
            "Whaze my servign'd for my myster'd;\n",
            "Stay,\n",
            "Shall die your father's disceof for thee? his head in the la \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCiBNos8w16I",
        "outputId": "7aa55966-a418-4f0c-9c96-9e782ca393b9"
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(start_strings[start], 200), '\\n')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " wh\n",
            " whellon formy:\n",
            "But her of new, giving in the starden, when this in the palumed,\n",
            "That have stone\n",
            "The death it to your consul I said,\n",
            "The fight\n",
            "Wister\n",
            "Now.\n",
            "\n",
            "VOLUMNIO:\n",
            "This like stors, for the same and fal \n",
            "\n",
            " ca\n",
            " carth of this\n",
            "Marchip, in the rese-to the king,\n",
            "And fived in\n",
            "all the comish, in fire before feurge you may the worth,\n",
            "A friend;\n",
            "And your son by thy brother of my father bid in earth 'twill be do churden \n",
            "\n",
            " ra\n",
            " ration what not parwing her sight in my flowed,\n",
            "And there in my flain, God father gone and my since the good promish'd in this no more pasts she say in leak to Rome, so? the feal'd in the war, crown now \n",
            "\n",
            " wh\n",
            " whell, but she lived with an answer it with, you sight us 'twish doth him to suloage of thrument of hour corn it men with the such sap your place!\n",
            "\n",
            "MIRANDA:\n",
            "I do shall pitch dest atter Hent so expite,\n",
            "W \n",
            "\n",
            " G\n",
            " Geat will be with me drunt--a that intrice of this dead her widio, this, and in thy proud Genton'd to Burning to see now, in his dead\n",
            "Ofe shall of that is repare the disbrong with the wiff of; I she;\n",
            "T \n",
            "\n",
            " ra\n",
            " rage, for I more the duke to surficure, begarted meth yea, if his sides grown:\n",
            "Which that rewell, who intent, in thrught; fore your shall greed whose unchress discorn; say you worth,\n",
            "Thereforrow:\n",
            "The ea \n",
            "\n",
            " I \n",
            " I it So be disport of this glass a littles:\n",
            "Then I have cry us missue.\n",
            "\n",
            "GONVER:\n",
            "Go like me have their poor me them sir,\n",
            "So man's purting to live more; forth the mind of mad! Yet the\n",
            "the Lord was leathed \n",
            "\n",
            " he\n",
            " hepless dismaster thou rick'd be good just hands your lively I am thingdee apon that in the due finst the fless more the lords of me,\n",
            "The seath.\n",
            "\n",
            "GREMIO:\n",
            "What is not to you:\n",
            "But not framies vicking on\n",
            "t \n",
            "\n",
            " he\n",
            " hep'd with so great, and you; were I was dispraince.\n",
            "\n",
            "ROMEO:\n",
            "Go forth this werter him offenty thouself;\n",
            "Such more, so vonder'd the confort for my my from which of his roud's words to be the fallows and  \n",
            "\n",
            " ca\n",
            " cathes or the sup your wings of his spires upon him like up our father by the queen up the very soldiest for the heart with a landded and a feoms my father that with me was do your goss set the lord of  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvYdq7YCL-7Y"
      },
      "source": [
        "# It does very well getting the play structure. It gets the name of a character, semi-colon and a new line most of the time.\n",
        "# The English sentences are mediocre but not terrible.\n",
        "# It puts an exclamation mark after the word 'mad'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}